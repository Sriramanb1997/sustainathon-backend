# Model Provider Configuration
# Choose your preferred AI model provider: 'ollama' or 'openai'
MODEL_PROVIDER=ollama

# Enable fallback to secondary provider if primary fails
ENABLE_FALLBACK=true

# Ollama Configuration (for local models)
OLLAMA_API_URL=http://127.0.0.1:11434/api/generate
OLLAMA_MODEL=mistral:7b
OLLAMA_MAX_RETRIES=3
OLLAMA_TIMEOUT=30
OLLAMA_RETRY_DELAY=2
OLLAMA_HEALTH_CHECK_TIMEOUT=15

# OpenAI Configuration (for cloud API)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=1500
OPENAI_TEMPERATURE=0.7

# Cache and Rate Limiting
CACHE_DURATION=5
MIN_REQUEST_INTERVAL=1

# Frontend Configuration
FRONTEND_URL=http://localhost:5173

# Google OAuth Configuration (existing)
# Add your existing Google OAuth credentials here
